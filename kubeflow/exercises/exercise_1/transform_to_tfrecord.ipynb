{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200a5493-68d0-4350-94f3-2a89c05adef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a8db69-1257-4971-a53d-a50de198e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHARDS = 5\n",
    "CLASSES = [b'angel', b'cat', b'crown', b'the_eiffel_tower', b'the_mona_lisa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bfcbbe-7d26-43dc-95db-bac62dd85bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_PROJECT_ID = \"<TO DEFINE>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79fb4a7-a4a5-4743-9ce8-8f6507684600",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_TRAINING_PATTERN = f'gs://{GCS_PROJECT_ID}/raw_images/training_data/*/*.png'\n",
    "GCS_TRAINING_TFRECORDS = f'gs://{GCS_PROJECT_ID}/tfrecord_data/training_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bb6268-9c40-43f3-a4b1-b18e9bd19b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_images = len(tf.io.gfile.glob(GCS_TRAINING_PATTERN))\n",
    "shard_size = math.ceil(1.0 * nb_images / SHARDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23c44b7-41ef-4fda-ab56-7fc53a9a5086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images are arranged in folders with corresponding labels\n",
    "def decode_image_and_label(filename):\n",
    "    bits = tf.io.read_file(filename)\n",
    "    image = tf.io.decode_png(bits)\n",
    "    label = tf.strings.split(tf.expand_dims(filename, axis=-1), sep='/')\n",
    "    label = label.values[-2]\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f23006-3523-4178-93d0-fac3991f4ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recompress_image(image, label):\n",
    "    image = tf.cast(image, tf.uint8)\n",
    "    image = tf.image.encode_jpeg(image, optimize_size=True, chroma_downsampling=False)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e284e9-fda4-4dc8-aeaf-d624aa53ab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.train.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c91fde0-2f95-4a47-91b2-077a0b61122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tfrecord(img_bytes, label):  \n",
    "    class_num = np.argmax(np.array(CLASSES)==label) \n",
    "    one_hot_class = np.eye(len(CLASSES))[class_num]\n",
    "    \n",
    "    feature = {\n",
    "      \"image\": _bytes_feature([img_bytes]), \n",
    "      \"class_num\": _int64_feature([class_num]),\n",
    "      \"label\": _bytes_feature([label]),         \n",
    "      \"one_hot_class\": _float_feature(one_hot_class.tolist())\n",
    "    }\n",
    "    \n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4794462b-a0a5-41e8-a861-bb6478d92184",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = tf.data.Dataset.list_files(GCS_TRAINING_PATTERN, seed=35155) # This also shuffles the images\n",
    "quickdraw_dataset = filenames.map(decode_image_and_label, num_parallel_calls=AUTOTUNE)\n",
    "quickdraw_dataset = quickdraw_dataset.map(recompress_image, num_parallel_calls=AUTOTUNE)\n",
    "# sharding: there will be one \"batch\" of images per file \n",
    "quickdraw_dataset = quickdraw_dataset.batch(shard_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac55d13b-0d0c-4606-b4e1-e5fd3dc5edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataset(dataset, filepath):\n",
    "    print(f'Starting writing {datetime.datetime.now().strftime(\"%H:%M:%S\")}')\n",
    "    dataset = dataset.enumerate()\n",
    "    for shard, (image, label) in dataset:\n",
    "        shard_size = image.numpy().shape[0]\n",
    "        filename = filepath + f\"quickdraw_dataset{str(shard.numpy()).rjust(2, '0')}_{shard_size}.tfrec\"\n",
    "        print(f'Starting file writing {datetime.datetime.now().strftime(\"%H:%M:%S\")}')\n",
    "\n",
    "        with tf.io.TFRecordWriter(filename) as tf_writer:\n",
    "            for i in range(shard_size):\n",
    "                example = to_tfrecord(image.numpy()[i], label.numpy()[i])\n",
    "                tf_writer.write(example.SerializeToString())\n",
    "            print(f'Wrote file {filename} containing {shard_size} records')\n",
    "            print(f'Wrote file at {datetime.datetime.now().strftime(\"%H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0380594e-4c93-4345-a0cd-af61388619ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataset(quickdraw_dataset, GCS_TRAINING_TFRECORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90c4f0c-6c43-4b6c-b4d8-9eb66449cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_VALIDATION_PATTERN = f'gs://{GCS_PROJECT_ID}/raw_images/validation_data/*/*.png'\n",
    "GCS_VALIDATION_TFRECORDS = f'gs://{GCS_PROJECT_ID}/tfrecord_data/validation_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56960559-fa04-4a73-813c-4d88f1e9d75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_images_valid = len(tf.io.gfile.glob(GCS_VALIDATION_PATTERN))\n",
    "shard_size_valid = math.ceil(1.0 * nb_images_valid / SHARDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1310f36f-fedd-45e4-9d47-ea36068b0308",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_valid = tf.data.Dataset.list_files(GCS_VALIDATION_PATTERN, seed=35155) # This also shuffles the images\n",
    "quickdraw_valid_dataset = filenames_valid.map(decode_image_and_label, num_parallel_calls=AUTOTUNE)\n",
    "quickdraw_valid_dataset = quickdraw_valid_dataset.map(recompress_image, num_parallel_calls=AUTOTUNE)\n",
    "quickdraw_valid_dataset = quickdraw_valid_dataset.batch(shard_size_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6a9368-b4e0-49d5-9e63-d98b2df689f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataset(quickdraw_valid_dataset, GCS_VALIDATION_TFRECORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3bccd0-5c6b-4b4e-901d-965b8adf94b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
