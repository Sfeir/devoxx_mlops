{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aa03a6a-618b-40bd-98b1-8ff909381315",
   "metadata": {},
   "source": [
    "# Quickdraw model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1e9423f-c0e9-4a08-a610-e9c3702ca5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbbaa148-b1a6-4a47-82e3-a2099ad1d473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables initialization\n",
    "curr_date = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "BUCKET_NAME = '<TO DEFINE>'\n",
    "GCS_TRAINING_DATA = f'gs://{BUCKET_NAME}/tfrecord_data/training_data/'\n",
    "GCS_VALIDATION_DATA = f'gs://{BUCKET_NAME}/tfrecord_data/validation_data/'\n",
    "GCS_MODEL_DATA_PATH = f'gs://{BUCKET_NAME}/gcs_model_data/quickdraw_classifier_{curr_date}/'\n",
    "\n",
    "batch_size = 50\n",
    "validation_batch_size = 20\n",
    "training_ds_size = 25000\n",
    "validation_ds_size = 5000\n",
    "img_height = 64\n",
    "img_width = 64\n",
    "nb_classes = 5\n",
    "lr = 0.001\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3a2d460-cc76-4919-a8f8-699e45d6bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord(example, img_size):\n",
    "    \"\"\"\n",
    "    Parse tf record that represents an image of size img_size,\n",
    "    and contains additional information such as : class number, label and one hot encoded class\n",
    "    :param example: TFRecord encoded image\n",
    "    :param img_size: image size\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"class_num\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"one_hot_class\": tf.io.VarLenFeature(tf.float32)\n",
    "    }\n",
    "\n",
    "    example = tf.io.parse_single_example(example, features)\n",
    "\n",
    "    image = tf.io.decode_jpeg(example['image'], channels=1)\n",
    "    image = tf.reshape(image, [*img_size, 1])\n",
    "\n",
    "    class_num = example['class_num']\n",
    "    label = example['label']\n",
    "    one_hot_class = tf.sparse.to_dense(example['one_hot_class'])\n",
    "\n",
    "    return image, class_num, label, one_hot_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "860633b4-9f6f-47d0-8963-7503ff01a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_tfrec_dataset(input_path: str, dataset_size: int, img_size: (int, int)):\n",
    "    \"\"\"\n",
    "    Read a dataset from Google Cloud Storage and preprocess it\n",
    "    :param input_path: input GCS path\n",
    "    :param dataset_size: input dataset_size\n",
    "    :param img_size: pair of image parameters (image height, image width)\n",
    "    :return: shuffled dataset with (image, one_hot_class) parameters\n",
    "    \"\"\"\n",
    "    option_no_order = tf.data.Options()\n",
    "    option_no_order.experimental_deterministic = False\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "    filenames = tf.io.gfile.glob(input_path + \"*.tfrec\")\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n",
    "    dataset = dataset.with_options(option_no_order)\n",
    "    dataset = dataset.map(lambda img: parse_tfrecord(img, img_size), num_parallel_calls=AUTOTUNE)\n",
    "    dataset = dataset.map(lambda image, class_num, label, one_hot_class: (image, one_hot_class))\n",
    "    dataset = dataset.shuffle(dataset_size)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0770488f-32f6-45fa-a7c8-4b7714429ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(img_height, img_width, nb_classes, lr):\n",
    "    \"\"\"\n",
    "    Creates keras model\n",
    "    :param img_height: image height\n",
    "    :param img_width: image width\n",
    "    :param nb_classes: number of classes\n",
    "    :param lr: optimizer learning rate\n",
    "    :return: model\n",
    "    \"\"\"\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Convolution2D(\n",
    "        input_shape=(img_height, img_width, 1),\n",
    "        kernel_size=5,\n",
    "        filters=32,\n",
    "        padding='same',\n",
    "        activation=tf.keras.activations.relu\n",
    "    ))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))\n",
    "\n",
    "    model.add(tf.keras.layers.Convolution2D(\n",
    "        kernel_size=3,\n",
    "        filters=32,\n",
    "        padding='same',\n",
    "        activation=tf.keras.activations.relu,\n",
    "    ))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))\n",
    "\n",
    "    model.add(tf.keras.layers.Convolution2D(\n",
    "        kernel_size=3,\n",
    "        filters=64,\n",
    "        padding='same',\n",
    "        activation=tf.keras.activations.relu\n",
    "    ))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=2, strides=2))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(units=512, activation=tf.keras.activations.relu))\n",
    "    model.add(tf.keras.layers.Dense(units=nb_classes, activation=tf.keras.activations.softmax))\n",
    "\n",
    "    rms_prop_optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=rms_prop_optimizer,\n",
    "        loss=tf.keras.losses.categorical_crossentropy,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbff42ad-72da-405d-a1e9-e1061458fd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 16:49:19.928862: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    499/Unknown - 13s 7ms/step - loss: 3.2550 - accuracy: 0.6499"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 16:49:30.859536: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs://devoxx_poc/gcs_model_data/quickdraw_classifier_20220417_164912/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs://devoxx_poc/gcs_model_data/quickdraw_classifier_20220417_164912/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 20s 20ms/step - loss: 3.2496 - accuracy: 0.6504 - val_loss: 0.4681 - val_accuracy: 0.8490\n",
      "Epoch 2/5\n",
      "497/500 [============================>.] - ETA: 0s - loss: 0.2948 - accuracy: 0.9090INFO:tensorflow:Assets written to: gs://devoxx_poc/gcs_model_data/quickdraw_classifier_20220417_164912/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs://devoxx_poc/gcs_model_data/quickdraw_classifier_20220417_164912/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 9s 16ms/step - loss: 0.2955 - accuracy: 0.9087 - val_loss: 0.2748 - val_accuracy: 0.9142\n",
      "Epoch 3/5\n",
      "497/500 [============================>.] - ETA: 0s - loss: 0.2079 - accuracy: 0.9352INFO:tensorflow:Assets written to: gs://devoxx_poc/gcs_model_data/quickdraw_classifier_20220417_164912/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs://devoxx_poc/gcs_model_data/quickdraw_classifier_20220417_164912/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 9s 16ms/step - loss: 0.2085 - accuracy: 0.9350 - val_loss: 0.2086 - val_accuracy: 0.9352\n",
      "Epoch 4/5\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 0.1718 - accuracy: 0.9468 - val_loss: 0.2906 - val_accuracy: 0.9288\n",
      "Epoch 5/5\n",
      "500/500 [==============================] - 5s 9ms/step - loss: 0.1456 - accuracy: 0.9545 - val_loss: 0.2113 - val_accuracy: 0.9396\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.get_strategy()\n",
    "\n",
    "logging.info(f\"Reading training dataset at {GCS_TRAINING_DATA}\")\n",
    "training_dataset = get_img_tfrec_dataset(GCS_TRAINING_DATA, training_ds_size, (img_height, img_width))\n",
    "training_dataset = training_dataset.batch(batch_size)\n",
    "\n",
    "logging.info(f\"Reading validation dataset at {GCS_VALIDATION_DATA}\")\n",
    "validation_dataset = get_img_tfrec_dataset(GCS_VALIDATION_DATA, validation_ds_size, (img_height, img_width))\n",
    "validation_dataset = validation_dataset.batch(validation_batch_size)\n",
    "\n",
    "logging.info(f\"Defining checkpoint and early stopping callbacks\")\n",
    "gcs_checkpoint_path = os.path.join(GCS_MODEL_DATA_PATH, \"model\", \"\")\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(gcs_checkpoint_path, save_best_only=True)\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy', patience=2, restore_best_weights=True\n",
    ")\n",
    "with strategy.scope():\n",
    "    model = create_model(img_height, img_width, nb_classes, lr)\n",
    "\n",
    "logging.info(\"Starting model fitting ...\")\n",
    "history = model.fit(\n",
    "    training_dataset,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# save metric for hyperparemeter tuning\n",
    "#hp_metric = history.history['val_accuracy'][-1]\n",
    "#\n",
    "#hpt = hypertune.HyperTune()\n",
    "#hpt.report_hyperparameter_tuning_metric(hyperparameter_metric_tag='val_accuracy',\n",
    "#                                        metric_value=hp_metric,\n",
    "#                                        global_step=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ebfaf46-b0bf-4bea-8bdf-05a3211b4955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('crown', 0.9999999), ('cat', 9.150056e-08), ('The Mona Lisa', 7.506949e-11), ('angel', 4.0674842e-11), ('The Eiffel Tower', 4.4128125e-15)]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "\n",
    "img = image.load_img(\"../testing_data/crown/crown_6004.png\", color_mode='grayscale',target_size=[img_height, img_width, 1])\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "images = np.vstack([x])\n",
    "probabilities = model.predict(images, batch_size=1)[0]\n",
    "img_classes = ['angel', 'cat', 'crown', 'The Eiffel Tower', 'The Mona Lisa']\n",
    "\n",
    "probabilities_with_classes = zip(img_classes, probabilities)\n",
    "sorted_probabilities = sorted(probabilities_with_classes,\n",
    "                              key=itemgetter(1),\n",
    "                              reverse=True)\n",
    "\n",
    "print(sorted_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2827dc7-f408-4653-aeda-6702a1ab8fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
